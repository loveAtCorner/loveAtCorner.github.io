<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Tech on YuTian Blog</title>
    <link>https://loveAtCorner.github.io/categories/tech/</link>
    <description>Recent content in Tech on YuTian Blog</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 15 Jul 2024 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://loveAtCorner.github.io/categories/tech/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>大模型衍生工具————代码翻译</title>
      <link>https://loveAtCorner.github.io/2024/07/15/LLMs_tools_code_interpreter/</link>
      <pubDate>Mon, 15 Jul 2024 00:00:00 +0000</pubDate>
      <guid>https://loveAtCorner.github.io/2024/07/15/LLMs_tools_code_interpreter/</guid>
      <description>源码解析工具 工具介绍 核心功能——源代码翻译 脚本级别的功能概括 函数/类级别的功能枚举 使用方法 前置条件 vllms框架启动的 qwen1.5-32b</description>
    </item>
    <item>
      <title>大模型衍生工具————多轮对话接口</title>
      <link>https://loveAtCorner.github.io/2024/07/15/LLMs_tools_code_interpreter/</link>
      <pubDate>Wed, 03 Jul 2024 00:00:00 +0000</pubDate>
      <guid>https://loveAtCorner.github.io/2024/07/15/LLMs_tools_code_interpreter/</guid>
      <description>源码解析工具 工具介绍 核心功能——源代码翻译 脚本级别的功能概括 函数/类级别的功能枚举 使用方法 前置条件 vllms框架启动的 qwen1.5-32b</description>
    </item>
    <item>
      <title>vllm实操</title>
      <link>https://loveAtCorner.github.io/2024/07/01/vllm/</link>
      <pubDate>Mon, 01 Jul 2024 00:00:00 +0000</pubDate>
      <guid>https://loveAtCorner.github.io/2024/07/01/vllm/</guid>
      <description>vllm操作指南 一、构建基础镜像 dockerhub下载地址 docker pull vllm/vllm-openai:v0.5.3 二. 下载模型参数 在电脑可以访问外网的前提下，建议使用 pycrawlers ，从 huggingface 下载模型参数，下</description>
    </item>
    <item>
      <title>ollama实操</title>
      <link>https://loveAtCorner.github.io/2024/06/28/ollama/</link>
      <pubDate>Fri, 28 Jun 2024 00:00:00 +0000</pubDate>
      <guid>https://loveAtCorner.github.io/2024/06/28/ollama/</guid>
      <description>ollama操作指南 一、如何在windows系统上安装 ollama 一.下载 Ollama 访问 https://ollama.com/download ，选择 Windows，单击 “Download for Windows (Preview)”</description>
    </item>
    <item>
      <title>大模型接口</title>
      <link>https://loveAtCorner.github.io/2024/06/27/LLMs_api/</link>
      <pubDate>Thu, 27 Jun 2024 00:00:00 +0000</pubDate>
      <guid>https://loveAtCorner.github.io/2024/06/27/LLMs_api/</guid>
      <description>开发大模型API接口开发思路 第一步、调用开源模型 开源大模型 from transformers import AutoModelForCausalLM, AutoTokenizer from transformers.generation import GenerationConfig model_path = os.path.join(current_path, &amp;#34;models/Qwen-7B-Chat&amp;#34;) # Model names: &amp;#34;Qwen/Qwen-7B-Chat&amp;#34;, &amp;#34;Qwen/Qwen-14B-Chat&amp;#34; tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True) # use bf16 # model = AutoModelForCausalLM.from_pretrained(model_path, device_map=&amp;#34;auto&amp;#34;, trust_remote_code=True, bf16=True).eval() # use fp16 # model = AutoModelForCausalLM.from_pretrained(model_path, device_map=&amp;#34;auto&amp;#34;, trust_remote_code=True,</description>
    </item>
    <item>
      <title>认识大模型</title>
      <link>https://loveAtCorner.github.io/2024/06/26/LLMs/</link>
      <pubDate>Wed, 26 Jun 2024 00:00:00 +0000</pubDate>
      <guid>https://loveAtCorner.github.io/2024/06/26/LLMs/</guid>
      <description>理解大模型：超越传统思维的变革 在谈到大模型的训练和应用时，许多人常常将其与传统的数据存储方式相混淆，认为大模型的训练类似于将数据存入硬盘中，</description>
    </item>
    <item>
      <title>实体命名识别技术介绍</title>
      <link>https://loveAtCorner.github.io/2024/06/23/introducing-the-ner-technology/</link>
      <pubDate>Sun, 23 Jun 2024 00:00:00 +0000</pubDate>
      <guid>https://loveAtCorner.github.io/2024/06/23/introducing-the-ner-technology/</guid>
      <description>NER案例 例子：命名实体识别（NER） 假设我们有如下句子： &amp;#34;John lives in New York.&amp;#34; 目标是识别出句子中的命名实体，并将其标注为对应的标签。对于这个例子，我们</description>
    </item>
    <item>
      <title>内网穿透</title>
      <link>https://loveAtCorner.github.io/2023/05/13/internal-network-penetration/</link>
      <pubDate>Sat, 13 May 2023 00:00:00 +0000</pubDate>
      <guid>https://loveAtCorner.github.io/2023/05/13/internal-network-penetration/</guid>
      <description>为什么需要内网穿透功能 从公网中访问自己的私有设备向来是一件难事儿。 自己的主力台式机、NAS等等设备，它们可能处于路由器后，或者运营商因为IP</description>
    </item>
    <item>
      <title>conda管理python环境</title>
      <link>https://loveAtCorner.github.io/2023/05/11/introducing-conda/</link>
      <pubDate>Thu, 11 May 2023 00:00:00 +0000</pubDate>
      <guid>https://loveAtCorner.github.io/2023/05/11/introducing-conda/</guid>
      <description>如果你已经在本地电脑上配好了虚拟环境A，并且想要备份环境A或者让别人直接使用你配好的环境A，可以采用以下三种方式： 一、环境迁移—快照 使用 conda create</description>
    </item>
  </channel>
</rss>
